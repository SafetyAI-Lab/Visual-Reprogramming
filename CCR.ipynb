{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9211760",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0510c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.225946Z",
     "start_time": "2025-01-13T08:04:45.517747Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标准库导入\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "# 额外的标准库导入\n",
    "import six\n",
    "from PIL import Image\n",
    "\n",
    "# 第三方库导入\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "# 本地模块导入（如果有需要，可以在这里添加）\n",
    "# from your_local_module import your_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad06235",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb5aa49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.233501Z",
     "start_time": "2025-01-13T08:04:48.227874Z"
    }
   },
   "outputs": [],
   "source": [
    "# 手动设置参数\n",
    "class Args:\n",
    "    network = \"resnet18\"# choices=[\"resnet18\", \"resnet50\", \"ViT_B32\"]\n",
    "    dataset = \"flowers102\" # choices=[\"cifar10\", \"cifar100\", \"gtsrb\", \"svhn\", \"food101\", \"eurosat\", \"sun397\", \"UCF101\", \"flowers102\", \"DTD\", \"oxfordpets\"]\n",
    "    batchsize = 224\n",
    "    seed = 42\n",
    "    patch_size = 8\n",
    "    attribute_channels = 3\n",
    "    mapping_method = \"ilm\"\n",
    "    data_path = \"/dataset/\"\n",
    "    results_path = \"./results\"\n",
    "    model_dir = \"/model_pth/\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_config(pretrained):\n",
    "    '''\n",
    "\n",
    "    Args:\n",
    "        dataset: string of the dataset name\n",
    "        pretrained: string of the pretrained model's name\n",
    "\n",
    "    Returns:\n",
    "        attribute_layers: the layer number of the attribute network\n",
    "        epochs: number of training epochs\n",
    "        lr: learning rate of reprogramming\n",
    "        attr_lr: learning rate of attribute network\n",
    "        attr_gamma: weight decay of attribute network\n",
    "    '''\n",
    "    epochs = 200\n",
    "    lr = 0.01\n",
    "\n",
    "    if pretrained == 'ViT_B32':\n",
    "        attribute_layers = 6\n",
    "        attr_lr = 0.001\n",
    "        attr_gamma = 1\n",
    "    else:\n",
    "        attribute_layers = 5\n",
    "        attr_lr = 0.01\n",
    "        attr_gamma = 0.1\n",
    "\n",
    "    return attribute_layers, epochs, lr, attr_lr, attr_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e998216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8a8ded",
   "metadata": {},
   "source": [
    "# const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a2b704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.306429Z",
     "start_time": "2025-01-13T08:04:48.235463Z"
    }
   },
   "outputs": [],
   "source": [
    "GTSRB_LABEL_MAP = {\n",
    "    '0': '20_speed',\n",
    "    '1': '30_speed',\n",
    "    '2': '50_speed',\n",
    "    '3': '60_speed',\n",
    "    '4': '70_speed',\n",
    "    '5': '80_speed',\n",
    "    '6': '80_lifted',\n",
    "    '7': '100_speed',\n",
    "    '8': '120_speed',\n",
    "    '9': 'no_overtaking_general',\n",
    "    '10': 'no_overtaking_trucks',\n",
    "    '11': 'right_of_way_crossing',\n",
    "    '12': 'right_of_way_general',\n",
    "    '13': 'give_way',\n",
    "    '14': 'stop',\n",
    "    '15': 'no_way_general',\n",
    "    '16': 'no_way_trucks',\n",
    "    '17': 'no_way_one_way',\n",
    "    '18': 'attention_general',\n",
    "    '19': 'attention_left_turn',\n",
    "    '20': 'attention_right_turn',\n",
    "    '21': 'attention_curvy',\n",
    "    '22': 'attention_bumpers',\n",
    "    '23': 'attention_slippery',\n",
    "    '24': 'attention_bottleneck',\n",
    "    '25': 'attention_construction',\n",
    "    '26': 'attention_traffic_light',\n",
    "    '27': 'attention_pedestrian',\n",
    "    '28': 'attention_children',\n",
    "    '29': 'attention_bikes',\n",
    "    '30': 'attention_snowflake',\n",
    "    '31': 'attention_deer',\n",
    "    '32': 'lifted_general',\n",
    "    '33': 'turn_right',\n",
    "    '34': 'turn_left',\n",
    "    '35': 'turn_straight',\n",
    "    '36': 'turn_straight_right',\n",
    "    '37': 'turn_straight_left',\n",
    "    '38': 'turn_right_down',\n",
    "    '39': 'turn_left_down',\n",
    "    '40': 'turn_circle',\n",
    "    '41': 'lifted_no_overtaking_general',\n",
    "    '42': 'lifted_no_overtaking_trucks'\n",
    "}\n",
    "\n",
    "IMAGENETCLASSES = ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'water ouzel', 'kite', 'bald eagle', 'vulture', 'great grey owl', 'European fire salamander', 'common newt', 'eft', 'spotted salamander', 'axolotl', 'bullfrog', 'tree frog', 'tailed frog', 'loggerhead', 'leatherback turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'common iguana', 'American chameleon', 'whiptail', 'agama', 'frilled lizard', 'alligator lizard', 'Gila monster', 'green lizard', 'African chameleon', 'Komodo dragon', 'African crocodile', 'American alligator', 'triceratops', 'thunder snake', 'ringneck snake', 'hognose snake', 'green snake', 'king snake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'rock python', 'Indian cobra', 'green mamba', 'sea snake', 'horned viper', 'diamondback', 'sidewinder', 'trilobite', 'harvestman', 'scorpion', 'black and gold garden spider', 'barn spider', 'garden spider', 'black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie chicken', 'peacock', 'quail', 'partridge', 'African grey', 'macaw', 'sulphur-crested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'drake', 'red-breasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'Dungeness crab', 'rock crab', 'fiddler crab', 'king crab', 'American lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'American egret', 'bittern', 'crane', 'limpkin', 'European gallinule', 'American coot', 'bustard', 'ruddy turnstone', 'red-backed sandpiper', 'redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'Chihuahua', 'Japanese spaniel', 'Maltese dog', 'Pekinese', 'Shih-Tzu', 'Blenheim spaniel', 'papillon', 'toy terrier', 'Rhodesian ridgeback', 'Afghan hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-and-tan coonhound', 'Walker hound', 'English foxhound', 'redbone', 'borzoi', 'Irish wolfhound', 'Italian greyhound', 'whippet', 'Ibizan hound', 'Norwegian elkhound', 'otterhound', 'Saluki', 'Scottish deerhound', 'Weimaraner', 'Staffordshire bullterrier', 'American Staffordshire terrier', 'Bedlington terrier', 'Border terrier', 'Kerry blue terrier', 'Irish terrier', 'Norfolk terrier', 'Norwich terrier', 'Yorkshire terrier', 'wire-haired fox terrier', 'Lakeland terrier', 'Sealyham terrier', 'Airedale', 'cairn', 'Australian terrier', 'Dandie Dinmont', 'Boston bull', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'Scotch terrier', 'Tibetan terrier', 'silky terrier', 'soft-coated wheaten terrier', 'West Highland white terrier', 'Lhasa', 'flat-coated retriever', 'curly-coated retriever', 'golden retriever', 'Labrador retriever', 'Chesapeake Bay retriever', 'German short-haired pointer', 'vizsla', 'English setter', 'Irish setter', 'Gordon setter', 'Brittany spaniel', 'clumber', 'English springer', 'Welsh springer spaniel', 'cocker spaniel', 'Sussex spaniel', 'Irish water spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old English sheepdog', 'Shetland sheepdog', 'collie', 'Border collie', 'Bouvier des Flandres', 'Rottweiler', 'German shepherd', 'Doberman', 'miniature pinscher', 'Greater Swiss Mountain dog', 'Bernese mountain dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull mastiff', 'Tibetan mastiff', 'French bulldog', 'Great Dane', 'Saint Bernard', 'Eskimo dog', 'malamute', 'Siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon griffon', 'Pembroke', 'Cardigan', 'toy poodle', 'miniature poodle', 'standard poodle', 'Mexican hairless', 'timber wolf', 'white wolf', 'red wolf', 'coyote', 'dingo', 'dhole', 'African hunting dog', 'hyena', 'red fox', 'kit fox', 'Arctic fox', 'grey fox', 'tabby', 'tiger cat', 'Persian cat', 'Siamese cat', 'Egyptian cat', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'American black bear', 'ice bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'long-horned beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket', 'walking stick', 'cockroach', 'mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'admiral', 'ringlet', 'monarch', 'cabbage butterfly', 'sulphur butterfly', 'lycaenid', 'starfish', 'sea urchin', 'sea cucumber', 'wood rabbit', 'hare', 'Angora', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'sorrel', 'zebra', 'hog', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram', 'bighorn', 'ibex', 'hartebeest', 'impala', 'gazelle', 'Arabian camel', 'llama', 'weasel', 'mink', 'polecat', 'black-footed ferret', 'otter', 'skunk', 'badger', 'armadillo', 'three-toed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas', 'baboon', 'macaque', 'langur', 'colobus', 'proboscis monkey', 'marmoset', 'capuchin', 'howler monkey', 'titi', 'spider monkey', 'squirrel monkey', 'Madagascar cat', 'indri', 'Indian elephant', 'African elephant', 'lesser panda', 'giant panda', 'barracouta', 'eel', 'coho', 'rock beauty', 'anemone fish', 'sturgeon', 'gar', 'lionfish', 'puffer', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibian', 'analog clock', 'apiary', 'apron', 'ashcan', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint', 'Band Aid', 'banjo', 'bannister', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'barrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathing cap', 'bath towel', 'bathtub', 'beach wagon', 'beacon', 'beaker', 'bearskin', 'beer bottle', 'beer glass', 'bell cote', 'bib', 'bicycle-built-for-two', 'bikini', 'binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsled', 'bolo tie', 'bonnet', 'bookcase', 'bookshop', 'bottlecap', 'bow', 'bow tie', 'brass', 'brassiere', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'bullet train', 'butcher shop', 'cab', 'caldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', \"carpenter's kit\", 'carton', 'car wheel', 'cash machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'CD player', 'cello', 'cellular telephone', 'chain', 'chainlink fence', 'chain mail', 'chain saw', 'chest', 'chiffonier', 'chime', 'china cabinet', 'Christmas stocking', 'church', 'cinema', 'cleaver', 'cliff dwelling', 'cloak', 'clog', 'cocktail shaker', 'coffee mug', 'coffeepot', 'coil', 'combination lock', 'computer keyboard', 'confectionery', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'crane', 'crash helmet', 'crate', 'crib', 'Crock Pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishrag', 'dishwasher', 'disk brake', 'dock', 'dogsled', 'dome', 'doormat', 'drilling platform', 'drum', 'drumstick', 'dumbbell', 'Dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso maker', 'face powder', 'feather boa', 'file', 'fireboat', 'fire engine', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'four-poster', 'freight car', 'French horn', 'frying pan', 'fur coat', 'garbage truck', 'gasmask', 'gas pump', 'goblet', 'go-kart', 'golf ball', 'golfcart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'grille', 'grocery store', 'guillotine', 'hair slide', 'hair spray', 'half track', 'hammer', 'hamper', 'hand blower', 'hand-held computer', 'handkerchief', 'hard disc', 'harmonica', 'harp', 'harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal bar', 'horse cart', 'hourglass', 'iPod', 'iron', \"jack-o'-lantern\", 'jean', 'jeep', 'jersey', 'jigsaw puzzle', 'jinrikisha', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'liner', 'lipstick', 'Loafer', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'magnetic compass', 'mailbag', 'mailbox', 'maillot', 'maillot', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine chest', 'megalith', 'microphone', 'microwave', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'Model T', 'modem', 'monastery', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito net', 'motor scooter', 'mountain bike', 'mountain tent', 'mouse', 'mousetrap', 'moving van', 'muzzle', 'nail', 'neck brace', 'necklace', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'organ', 'oscilloscope', 'overskirt', 'oxcart', 'oxygen mask', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'passenger car', 'patio', 'pay-phone', 'pedestal', 'pencil box', 'pencil sharpener', 'perfume', 'Petri dish', 'photocopier', 'pick', 'pickelhaube', 'picket fence', 'pickup', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'ping-pong ball', 'pinwheel', 'pirate', 'pitcher', 'plane', 'planetarium', 'plastic bag', 'plate rack', 'plow', 'plunger', 'Polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'pop bottle', 'pot', \"potter's wheel\", 'power drill', 'prayer rug', 'printer', 'prison', 'projectile', 'projector', 'puck', 'punching bag', 'purse', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'rubber eraser', 'rugby ball', 'rule', 'running shoe', 'safe', 'safety pin', 'saltshaker', 'sandal', 'sarong', 'sax', 'scabbard', 'scale', 'school bus', 'schooner', 'scoreboard', 'screen', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe shop', 'shoji', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar dish', 'sombrero', 'soup bowl', 'space bar', 'space heater', 'space shuttle', 'spatula', 'speedboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'steel arch bridge', 'steel drum', 'stethoscope', 'stole', 'stone wall', 'stopwatch', 'stove', 'strainer', 'streetcar', 'stretcher', 'studio couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension bridge', 'swab', 'sweatshirt', 'swimming trunks', 'swing', 'switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy', 'television', 'tennis ball', 'thatch', 'theater curtain', 'thimble', 'thresher', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toyshop', 'tractor', 'trailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'vase', 'vault', 'velvet', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'warplane', 'washbasin', 'washer', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'wig', 'window screen', 'window shade', 'Windsor tie', 'wine bottle', 'wing', 'wok', 'wooden spoon', 'wool', 'worm fence', 'wreck', 'yawl', 'yurt', 'web site', 'comic book', 'crossword puzzle', 'street sign', 'traffic light', 'book jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'ice lolly', 'French loaf', 'bagel', 'pretzel', 'cheeseburger', 'hotdog', 'mashed potato', 'head cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'Granny Smith', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate sauce', 'dough', 'meat loaf', 'pizza', 'potpie', 'burrito', 'red wine', 'espresso', 'cup', 'eggnog', 'alp', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeside', 'promontory', 'sandbar', 'seashore', 'valley', 'volcano', 'ballplayer', 'groom', 'scuba diver', 'rapeseed', 'daisy', \"yellow lady's slipper\", 'corn', 'acorn', 'hip', 'buckeye', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn', 'earthstar', 'hen-of-the-woods', 'bolete', 'ear', 'toilet tissue']\n",
    "\n",
    "CIFAR10CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "CIFAR100CLASSES = ['beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
    "                   'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
    "                   'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', 'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
    "                   'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
    "                   'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
    "                   'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
    "                   'fox', 'porcupine', 'possum', 'raccoon', 'skunk', 'crab', 'lobster', 'snail', 'spider', 'worm', 'baby',\n",
    "                   'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', 'hamster', 'mouse',\n",
    "                   'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle',\n",
    "                   'pickup truck', 'train', 'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "\n",
    "\n",
    "IMAGENETNORMALIZE = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa802b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4642dceb",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea41a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.348252Z",
     "start_time": "2025-01-13T08:04:48.308712Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import six\n",
    "def loads_data(buf):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buf: the output of `dumps`.\n",
    "    \"\"\"\n",
    "    return pickle.loads(buf)\n",
    "def prepare_additive_data(dataset, data_path, preprocess, test_process=None, batchsize = 256):\n",
    "    data_path = os.path.join(data_path, dataset)\n",
    "    if dataset == \"cifar10\":\n",
    "        train_data = datasets.CIFAR10(root = data_path, train = True, download = False, transform = preprocess)\n",
    "        test_data = datasets.CIFAR10(root = data_path, train = False, download = False, transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes),\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=2),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=2),\n",
    "        }\n",
    "        \n",
    "    elif dataset == \"cifar100\":\n",
    "        train_data = datasets.CIFAR100(root = data_path, train = True, download = False, transform = preprocess)\n",
    "        test_data = datasets.CIFAR100(root = data_path, train = False, download = False, transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes)\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=8),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=8),\n",
    "        }\n",
    "        \n",
    "    elif dataset == \"svhn\":\n",
    "        train_data = datasets.SVHN(root = data_path, split=\"train\", download = False, transform = preprocess)\n",
    "        test_data = datasets.SVHN(root = data_path, split=\"test\", download = False, transform = test_process)\n",
    "        class_names = [f'{i}' for i in range(10)]\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=8),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=8),\n",
    "        }\n",
    "        \n",
    "    elif dataset == \"gtsrb\":\n",
    "        train_data = datasets.GTSRB(root = data_path, split=\"train\", download = True, transform = preprocess)\n",
    "        test_data = datasets.GTSRB(root = data_path, split=\"test\", download = True, transform = test_process)\n",
    "        class_names = refine_classnames(list(GTSRB_LABEL_MAP.values()))\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=8),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=8),\n",
    "        }\n",
    "        \n",
    "    elif dataset in [\"food101\", \"eurosat\", \"sun397\", \"UCF101\", \"flowers102\"]:\n",
    "        train_data = COOPLMDBDataset(root = data_path, split=\"train\", transform = preprocess)\n",
    "        test_data = COOPLMDBDataset(root = data_path, split=\"test\", transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes),\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=8),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=8),\n",
    "        }\n",
    "\n",
    "    elif dataset in [\"DTD\", \"oxfordpets\"]:\n",
    "        train_data = COOPLMDBDataset(root = data_path, split=\"train\", transform = preprocess)\n",
    "        test_data = COOPLMDBDataset(root = data_path, split=\"test\", transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes),\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batchsize, shuffle = True, num_workers=8),\n",
    "            'test': DataLoader(test_data, batchsize, shuffle = False, num_workers=8),\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{dataset} not supported\")\n",
    "    return loaders, class_names, train_data, test_data\n",
    "\n",
    "class LMDBDataset(data.Dataset):\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
    "        super().__init__()\n",
    "        db_path = os.path.join(root, f\"{split}.lmdb\")\n",
    "        self.env = lmdb.open(db_path, subdir=os.path.isdir(db_path),\n",
    "                             readonly=True, lock=False,\n",
    "                             readahead=False, meminit=False)\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = loads_data(txn.get(b'__len__'))\n",
    "            self.keys = loads_data(txn.get(b'__keys__'))\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        env = self.env\n",
    "        with env.begin(write=False) as txn:\n",
    "            byteflow = txn.get(self.keys[index])\n",
    "\n",
    "        unpacked = loads_data(byteflow)\n",
    "\n",
    "        # load img\n",
    "        imgbuf = unpacked[0]\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "\n",
    "        # load label\n",
    "        target = unpacked[1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        # return img, target\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + self.db_path + ')'\n",
    "    \n",
    "class COOPLMDBDataset(LMDBDataset):\n",
    "    def __init__(self, root, split=\"train\", transform=None) -> None:\n",
    "        super().__init__(root, split, transform=transform)\n",
    "        with open(os.path.join(root, \"split.json\")) as f:\n",
    "            split_file = json.load(f)\n",
    "        idx_to_class = OrderedDict(sorted({s[-2]: s[-1] for s in split_file[\"test\"]}.items()))\n",
    "        self.classes = list(idx_to_class.values())\n",
    "\n",
    "def refine_classnames(class_names):\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_names[i] = class_name.lower().replace('_', ' ').replace('-', ' ')\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b0266",
   "metadata": {},
   "source": [
    "# label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd224aa6",
   "metadata": {},
   "source": [
    "## flm_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53c6d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.430591Z",
     "start_time": "2025-01-13T08:04:48.349515Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dist_matrix(fx, y):\n",
    "    fx = one_hot(torch.argmax(fx, dim = -1), num_classes=fx.size(-1))\n",
    "    dist_matrix = [fx[y==i].sum(0).unsqueeze(1) for i in range(len(y.unique()))]\n",
    "    dist_matrix = torch.cat(dist_matrix, dim=1)\n",
    "    return dist_matrix\n",
    "\n",
    "def predictive_distribution_based_multi_label_mapping(dist_matrix, mlm_num: int):\n",
    "    assert mlm_num * dist_matrix.size(1) <= dist_matrix.size(0), \"source label number not enough for mapping\"\n",
    "    mapping_matrix = torch.zeros_like(dist_matrix, dtype=int)\n",
    "    dist_matrix_flat = dist_matrix.flatten()\n",
    "    for _ in range(mlm_num * dist_matrix.size(1)):\n",
    "        loc = dist_matrix_flat.argmax().item()\n",
    "        loc = [loc // dist_matrix.size(1), loc % dist_matrix.size(1)]\n",
    "        mapping_matrix[loc[0], loc[1]] = 1\n",
    "        dist_matrix[loc[0]] = -1\n",
    "        if mapping_matrix[:, loc[1]].sum() == mlm_num:\n",
    "            dist_matrix[:, loc[1]] = -1\n",
    "    return mapping_matrix\n",
    "\n",
    "def generate_label_mapping_by_frequency(visual_prompt, network, data_loader, mapping_num = 1): # mapping_num=1: 1V1 match\n",
    "    device = next(visual_prompt.parameters()).device\n",
    "    if hasattr(network, \"eval\"):\n",
    "        network.eval()\n",
    "    fx0s = []\n",
    "    ys = []\n",
    "    pbar = tqdm(data_loader, total=len(data_loader), desc=f\"Frequency Label Mapping\", ncols=100) if len(data_loader) > 20 else data_loader\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            fx0 = network(visual_prompt(x))\n",
    "        fx0s.append(fx0)\n",
    "        ys.append(y)\n",
    "    fx0s = torch.cat(fx0s).cpu().float()\n",
    "    ys = torch.cat(ys).cpu().int()\n",
    "    if ys.size(0) != fx0s.size(0):\n",
    "        assert fx0s.size(0) % ys.size(0) == 0\n",
    "        ys = ys.repeat(int(fx0s.size(0) / ys.size(0)))\n",
    "    dist_matrix = get_dist_matrix(fx0s, ys)\n",
    "    pairs = torch.nonzero(predictive_distribution_based_multi_label_mapping(dist_matrix, mapping_num)) # (C, C) 原来i类对应现在的j类, j=0,1,...,C\n",
    "    mapping_sequence = pairs[:, 0][torch.sort(pairs[:, 1]).indices.tolist()]\n",
    "    return mapping_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e633e",
   "metadata": {},
   "source": [
    "## label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3617c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:48.439532Z",
     "start_time": "2025-01-13T08:04:48.431989Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_mapping_base(logits, mapping_sequence):\n",
    "    modified_logits = logits[:, mapping_sequence]\n",
    "    return modified_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca1d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc320e9",
   "metadata": {},
   "source": [
    "# data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2d2d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.353948Z",
     "start_time": "2025-01-13T08:04:48.440848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别名称: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "图像批次尺寸: torch.Size([224, 3, 224, 224]), 标签尺寸: torch.Size([224])\n"
     ]
    }
   ],
   "source": [
    "# 设备配置\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 设置图像大小\n",
    "imgsize = 384 if args.network == \"ViT_B32\" else 224\n",
    "\n",
    "# 定义预处理\n",
    "train_preprocess = transforms.Compose([\n",
    "    transforms.Resize((imgsize + 32, imgsize + 32)),\n",
    "    transforms.RandomCrop(imgsize),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if hasattr(x, 'convert') else x),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENETNORMALIZE['mean'], IMAGENETNORMALIZE['std']),\n",
    "])\n",
    "test_preprocess = transforms.Compose([\n",
    "    transforms.Resize((imgsize, imgsize)),\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if hasattr(x, 'convert') else x),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENETNORMALIZE['mean'], IMAGENETNORMALIZE['std']),\n",
    "])\n",
    "\n",
    "# 数据加载\n",
    "loaders, class_names,train_dataset,test_dataset = prepare_additive_data(\n",
    "    dataset=args.dataset,\n",
    "    data_path=args.data_path,         # 设置为默认的 'dataset' 文件夹\n",
    "    preprocess=train_preprocess,\n",
    "    test_process=test_preprocess,\n",
    "    batchsize = args.batchsize\n",
    "#     download=True\n",
    ")\n",
    "if len(class_names) == 1:\n",
    "    class_names = class_names[0]\n",
    "    \n",
    "print(\"类别名称:\", class_names)\n",
    "\n",
    "# 示例：遍历训练数据\n",
    "for images, labels in loaders['train']:\n",
    "    print(f\"图像批次尺寸: {images.size()}, 标签尺寸: {labels.size()}\")\n",
    "    break  # 仅显示第一个批次\n",
    "\n",
    "attribute_layers, epochs, lr, attr_lr, attr_gamma = get_config(args.network)\n",
    "\n",
    "save_path = os.path.join(args.results_path, args.dataset + args.network + args.mapping_method + str(args.seed) + str(args.attribute_channels) + str(attribute_layers) + str(args.patch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6620982",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9c183",
   "metadata": {},
   "source": [
    "## VisualPrompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0972d83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.365905Z",
     "start_time": "2025-01-13T08:04:50.355950Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttributeNet(nn.Module):\n",
    "    def __init__(self, layers=5, patch_size=8, channels=3):\n",
    "        super(AttributeNet, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        if self.layers == 5 and self.channels == 3:\n",
    "            self.conv6 = nn.Conv2d(64, 3, 3, 1, 1)\n",
    "        elif self.layers == 6:\n",
    "            self.conv5 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "            self.bn5 = nn.BatchNorm2d(128)\n",
    "            self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "            if self.channels == 3:\n",
    "                self.conv6 = nn.Conv2d(128, 3, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu1(y)\n",
    "        if self.patch_size in [2, 4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = self.relu2(y)\n",
    "        if self.patch_size in [4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.bn3(y)\n",
    "        y = self.relu3(y)\n",
    "        if self.patch_size in [8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.bn4(y)\n",
    "        y = self.relu4(y)\n",
    "        if self.patch_size in [16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        if self.layers == 6:\n",
    "            y = self.conv5(y)\n",
    "            y = self.bn5(y)\n",
    "            y = self.relu5(y)\n",
    "            if self.patch_size == 32:\n",
    "                y = self.pooling(y)\n",
    "\n",
    "        if self.channels == 3:\n",
    "            y = self.conv6(y)\n",
    "        elif self.channels == 1:\n",
    "            y = torch.mean(y, dim=1)\n",
    "        return y\n",
    "\n",
    "class InstancewiseVisualPrompt(nn.Module):\n",
    "    def __init__(self, size, layers=5, patch_size=8, channels=3):\n",
    "        '''\n",
    "        Args:\n",
    "            size: input image size\n",
    "            layers: the number of layers of mask-training CNN\n",
    "            patch_size: the size of patches with the same mask value\n",
    "            channels: 3 means that the mask value for RGB channels are different, 1 means the same\n",
    "            keep_watermark: whether to keep the reprogram (\\\\delta) in the model\n",
    "        '''\n",
    "        super(InstancewiseVisualPrompt, self).__init__()\n",
    "        if layers not in [5, 6]:\n",
    "            raise ValueError(\"Input layer number is not supported\")\n",
    "        if patch_size not in [1, 2, 4, 8, 16, 32]:\n",
    "            raise ValueError(\"Input patch size is not supported\")\n",
    "        if channels not in [1, 3]:\n",
    "            raise ValueError(\"Input channel number is not supported\")\n",
    "        if patch_size == 32 and layers != 6:\n",
    "            raise ValueError(\"Input layer number and patch size are conflict with each other\")\n",
    "\n",
    "        # Set the attribute mask CNN\n",
    "        self.patch_num = int(size / patch_size)\n",
    "        self.imagesize = size\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "        self.priority = AttributeNet(layers, patch_size, channels)\n",
    "\n",
    "        # Set reprogram (\\delta) according to the image size\n",
    "        self.size = size\n",
    "        self.program = torch.nn.Parameter(data=torch.zeros(3, size, size))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.priority(x).view(-1, self.channels, self.patch_num * self.patch_num, 1).expand(-1, 3, -1, self.patch_size * self.patch_size).view(-1, 3, self.patch_num, self.patch_num, self.patch_size, self.patch_size).transpose(3, 4)\n",
    "        attention = attention.reshape(-1, 3, self.imagesize, self.imagesize)\n",
    "        x = x + self.program * attention\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d07f1e",
   "metadata": {},
   "source": [
    "##  VisualPrompt-compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b90bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.393190Z",
     "start_time": "2025-01-13T08:04:50.367194Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AttributeNet_activation(nn.Module):\n",
    "    def __init__(self, layers=5, patch_size=8, channels=3, activation=nn.ReLU):\n",
    "        # activation=nn.LeakyReLU; activation=nn.ELU; activation=nn.GELU; activation=nn.SiLU; activation=nn.Mish\n",
    "        super(AttributeNet_activation, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "\n",
    "        # 初始化激活函数\n",
    "        self.activation = activation(inplace=True) if hasattr(activation, 'inplace') else activation()\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = self.activation\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = self.activation\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.relu3 = self.activation\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = self.activation\n",
    "        if self.layers == 5 and self.channels == 3:\n",
    "            self.conv6 = nn.Conv2d(64, 3, 3, 1, 1)\n",
    "        elif self.layers == 6:\n",
    "            self.conv5 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "            self.bn5 = nn.BatchNorm2d(128)\n",
    "            self.relu5 = self.activation\n",
    "\n",
    "            if self.channels == 3:\n",
    "                self.conv6 = nn.Conv2d(128, 3, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu1(y)\n",
    "        if self.patch_size in [2, 4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = self.relu2(y)\n",
    "        if self.patch_size in [4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.bn3(y)\n",
    "        y = self.relu3(y)\n",
    "        if self.patch_size in [8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.bn4(y)\n",
    "        y = self.relu4(y)\n",
    "        if self.patch_size in [16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        if self.layers == 6:\n",
    "            y = self.conv5(y)\n",
    "            y = self.bn5(y)\n",
    "            y = self.relu5(y)\n",
    "            if self.patch_size == 32:\n",
    "                y = self.pooling(y)\n",
    "\n",
    "        if self.channels == 3:\n",
    "            y = self.conv6(y)\n",
    "        elif self.channels == 1:\n",
    "            y = torch.mean(y, dim=1)\n",
    "        return y\n",
    "\n",
    "class VisualPrompt_compensation(nn.Module):\n",
    "    def __init__(self, size, layers=5, patch_size=8, channels=3, activation=nn.Mish):\n",
    "        super(VisualPrompt_compensation, self).__init__()\n",
    "        if layers not in [5, 6]:\n",
    "            raise ValueError(\"Input layer number is not supported\")\n",
    "        if patch_size not in [1, 2, 4, 8, 16, 32]:\n",
    "            raise ValueError(\"Input patch size is not supported\")\n",
    "        if channels not in [1, 3]:\n",
    "            raise ValueError(\"Input channel number is not supported\")\n",
    "        if patch_size == 32 and layers != 6:\n",
    "            raise ValueError(\"Input layer number and patch size are conflict with each other\")\n",
    "\n",
    "        # Set the attribute mask CNN\n",
    "        self.patch_num = int(size / patch_size)\n",
    "        self.imagesize = size\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "        self.priority = AttributeNet_activation(layers, patch_size, channels, activation=activation)\n",
    "\n",
    "        # Set reprogram (\\delta) according to the image size\n",
    "        self.size = size\n",
    "        self.program = torch.nn.Parameter(data=torch.zeros(3, size, size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.priority(x).view(-1, self.channels, self.patch_num * self.patch_num, 1).expand(-1, 3, -1, self.patch_size * self.patch_size).view(-1, 3, self.patch_num, self.patch_num, self.patch_size, self.patch_size).transpose(3, 4)\n",
    "        attention = attention.reshape(-1, 3, self.imagesize, self.imagesize)\n",
    "        Prompt_compensation = self.program * attention\n",
    "        return Prompt_compensation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2354a6",
   "metadata": {},
   "source": [
    "## Proportional Adjustment Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d897ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.402226Z",
     "start_time": "2025-01-13T08:04:50.395645Z"
    }
   },
   "outputs": [],
   "source": [
    "class PAC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PAC, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = PAC().to(device)\n",
    "# x = torch.rand(256, 3, 224, 224).to(device)\n",
    "# output = model(x)\n",
    "# print(output.shape)  # 输出: torch.Size([256, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98710328",
   "metadata": {},
   "source": [
    "##  SMM_Compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdfd9634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.410273Z",
     "start_time": "2025-01-13T08:04:50.403339Z"
    }
   },
   "outputs": [],
   "source": [
    "class SMM_compensation(nn.Module):\n",
    "    def __init__(self, network, visual_prompt, visual_prompt_comp, pac):\n",
    "        super(SMM_compensation, self).__init__()\n",
    "        self.network = network\n",
    "        self.visual_prompt = visual_prompt\n",
    "        self.visual_prompt_comp = visual_prompt_comp\n",
    "        self.mininet = pac\n",
    "\n",
    "    def forward(self, x, label_mapping, label_mapping_comp) -> torch.Tensor:\n",
    "        # SMM 模型\n",
    "        f_frozen = self.visual_prompt(x)  # f_frozen = x + self.program * attention  \n",
    "        logit_main = self.network(f_frozen)\n",
    "        X_main = label_mapping(logit_main)\n",
    "        \n",
    "        # SMM 模型的补偿部分\n",
    "        f_compensation = self.visual_prompt_comp(x)\n",
    "        logit_comp = self.network(f_compensation + x)\n",
    "        X_comp = label_mapping_comp(logit_comp)\n",
    "        \n",
    "        # 用于 alpha 学习的 pac\n",
    "        alpha = self.mininet(x).view(x.size(0), 1, 1, 1)  # 将 alpha 重塑为 [B, 1, 1, 1]\n",
    "       \n",
    "        Prompt_all = (alpha * (f_frozen - x) + (1 - alpha) * f_compensation) + x\n",
    "        output_class = label_mapping(self.network(Prompt_all))\n",
    "        \n",
    "        return output_class, X_main, X_comp, alpha.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a13f43",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bcd16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.420166Z",
     "start_time": "2025-01-13T08:04:50.411361Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, lambda_ce=1.0, lambda_mse=1.0, lambda_alpha=1.0):\n",
    "        \"\"\"\n",
    "        初始化 CustomLoss 类。\n",
    "\n",
    "        参数:\n",
    "            lambda_ce (float): 交叉熵损失的权重。\n",
    "            lambda_mse (float): 补偿损失的权重。\n",
    "            lambda_alpha (float): Alpha 损失的权重。\n",
    "        \"\"\"\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.lambda_ce = lambda_ce\n",
    "        self.lambda_mse = lambda_mse\n",
    "        self.lambda_alpha = lambda_alpha\n",
    "        self.c = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, output_class, X_main, X_comp, alpha, y, updating_part='all'):\n",
    "        \"\"\"\n",
    "        前向传播计算总损失及各个子损失。\n",
    "\n",
    "        参数:\n",
    "            output_class (torch.Tensor): 模型的分类输出，形状为 (batch_size, num_classes)。\n",
    "            X_main (torch.Tensor): 主流的特征输出，形状为 (batch_size, num_classes)。\n",
    "            X_comp (torch.Tensor): 补偿流的特征输出，形状为 (batch_size, num_classes)。\n",
    "            alpha (torch.Tensor): 模型预测的 alpha 值，形状为 (batch_size,)。\n",
    "            y (torch.Tensor): 真实的类别标签，形状为 (batch_size,)。\n",
    "            updating_part (str): 当前更新的部分，'visual_prompt' 或 'visual_prompt_comp'。\n",
    "\n",
    "        返回:\n",
    "            total_loss (torch.Tensor): 综合损失。\n",
    "        \"\"\"\n",
    "        if updating_part == 'visual_prompt':\n",
    "            # 仅计算主流的交叉熵损失\n",
    "            loss_ce_main = self.cross_entropy(X_main, y)\n",
    "            return loss_ce_main\n",
    "\n",
    "        elif updating_part == 'visual_prompt_comp':\n",
    "            # 计算完整的损失\n",
    "            # 1. 交叉熵分类损失\n",
    "            loss_ce_all = self.cross_entropy(output_class, y)\n",
    "\n",
    "            # 2. 补偿损失\n",
    "            Y_main = F.one_hot(y, num_classes=output_class.size(1)).float()  # One-Hot 编码\n",
    "            X_main_probs = F.softmax(X_main, dim=1)  # 主流概率分布\n",
    "            Y_diff = Y_main - X_main_probs  # 标签差异\n",
    "            X_comp_probs = F.softmax(X_comp, dim=1)  # 补偿流概率分布\n",
    "            loss_mse = self.mse(X_comp_probs, Y_diff)  # 均方误差损失\n",
    "\n",
    "            # 3. Alpha 损失（L2 范数）\n",
    "            output_class_probs = F.softmax(output_class, dim=1)  # 分类输出概率分布\n",
    "            diff = torch.norm(output_class_probs - X_main_probs, p=2, dim=1)  # 残差的 L2 范数\n",
    "            alpha_standard = torch.sigmoid(self.c*diff)  # 标准 alpha\n",
    "            loss_alpha = self.mse(alpha, alpha_standard)  # Alpha 损失\n",
    "\n",
    "            # 4. 综合损失\n",
    "            total_loss = (self.lambda_ce * loss_ce_all +\n",
    "                          self.lambda_mse * loss_mse +\n",
    "                          self.lambda_alpha * loss_alpha)\n",
    "            return total_loss\n",
    "\n",
    "        else:\n",
    "            # 计算所有损失（默认情况）\n",
    "            loss_ce_main = self.cross_entropy(X_main, y)\n",
    "            loss_ce_all = self.cross_entropy(output_class, y)\n",
    "            Y_main = F.one_hot(y, num_classes=output_class.size(1)).float()\n",
    "            X_main_probs = F.softmax(X_main, dim=1)\n",
    "            Y_diff = Y_main - X_main_probs\n",
    "            X_comp_probs = F.softmax(X_comp, dim=1)\n",
    "            loss_mse = self.mse(X_comp_probs, Y_diff)\n",
    "            output_class_probs = F.softmax(output_class, dim=1)\n",
    "            diff = torch.norm(output_class_probs - X_main_probs, p=2, dim=1)\n",
    "            alpha_standard = torch.sigmoid(self.c*diff)\n",
    "            loss_alpha = self.mse(alpha, alpha_standard)\n",
    "            total_loss = (self.lambda_ce * (loss_ce_main + loss_ce_all) +\n",
    "                          self.lambda_mse * loss_mse +\n",
    "                          self.lambda_alpha * loss_alpha)\n",
    "            return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480d966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "321474d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:50.430550Z",
     "start_time": "2025-01-13T08:04:50.421148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make dir\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(args.model_dir, exist_ok=True)\n",
    "logger = SummaryWriter(save_path)\n",
    "\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a87cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dcee2af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:04:51.334135Z",
     "start_time": "2025-01-13T08:04:50.431729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型权重已加载至: /home/yyh/Desktop/2022/ly/ICML/Code/model_pth/resnet18_weights.pth\n",
      "模型设备: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的模型并加载本地权重\n",
    "if args.network == \"resnet18\":\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "    network = resnet18(weights=None)  # 初始化模型，不加载预训练权重\n",
    "    weight_path = os.path.join(args.model_dir, \"resnet18_weights.pth\")\n",
    "elif args.network == \"resnet50\":\n",
    "    from torchvision.models import resnet50, ResNet50_Weights\n",
    "    network = resnet50(weights=None)  # 初始化模型，不加载预训练权重\n",
    "    weight_path = os.path.join(args.model_dir, \"resnet50_weights.pth\")\n",
    "elif args.network == \"ViT_B32\":\n",
    "    from pytorch_pretrained_vit import ViT\n",
    "    network = ViT('B_32_imagenet1k', pretrained=False)  # 初始化模型，不加载预训练权重\n",
    "    weight_path = os.path.join(args.model_dir, \"ViT_B32_weights.pth\")\n",
    "else:\n",
    "    raise NotImplementedError(f\"{args.network} is not supported\")\n",
    "\n",
    "# 检查权重文件是否存在\n",
    "if not os.path.exists(weight_path):\n",
    "    raise FileNotFoundError(f\"权重文件未找到: {weight_path}\")\n",
    "\n",
    "# 加载权重\n",
    "network.load_state_dict(torch.load(weight_path, map_location=device,weights_only=True), strict=False)\n",
    "network.to(device)\n",
    "\n",
    "print(f\"模型权重已加载至: {weight_path}\")\n",
    "print(f\"模型设备: {device}\")\n",
    "\n",
    "# 冻结网络参数\n",
    "network.requires_grad_(False)\n",
    "network.eval()\n",
    "\n",
    "# 4. 初始化模型组件\n",
    "visual_prompt = InstancewiseVisualPrompt(imgsize, attribute_layers, args.patch_size, args.attribute_channels).to(device)\n",
    "visual_prompt_comp = VisualPrompt_compensation(imgsize, attribute_layers, args.patch_size, args.attribute_channels).to(device)\n",
    "\n",
    "pac = PAC().to(device)\n",
    "model = SMM_compensation(network, visual_prompt, visual_prompt_comp, pac).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05374c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5f3f8de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:08:33.338747Z",
     "start_time": "2025-01-13T08:08:33.085809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载检查点：./results/cifar10resnet18ilm42358/best_AL_mish_resnet18_cifar10_1.pth\n"
     ]
    }
   ],
   "source": [
    "# 动态构建检查点文件名，添加运行后缀\n",
    "dataset_name = args.dataset  # 'DTD'\n",
    "checkpoint_path = os.path.join(save_path, f'best_AL_mish_{args.network}_{dataset_name}_2.pth')\n",
    "checkpoint_path_ckpt = os.path.join(save_path, f'ckpt_AL_mish_{args.network}_{dataset_name}.pth')\n",
    "\n",
    "if_test = False\n",
    "\n",
    "# 10. 检查是否有检查点存在\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"加载检查点：{checkpoint_path}\")\n",
    "    # 模型参数导入\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=True)\n",
    "    model.visual_prompt.load_state_dict(checkpoint['visual_prompt_dict'])\n",
    "    model.visual_prompt_comp.load_state_dict(checkpoint['visual_prompt_comp_dict'])\n",
    "    model.mininet.load_state_dict(checkpoint['mininet_dict'])\n",
    "    mapping_sequence = checkpoint.get(\"mapping_sequence\", None)\n",
    "    mapping_sequence_comp = checkpoint.get(\"mapping_sequence_comp\", None)\n",
    "    # 继续下一个epoch\n",
    "    epoch_start = checkpoint.get(\"epoch\", 0) + 1  \n",
    "    best_acc = checkpoint.get(\"best_acc\", 0.0)\n",
    "    train_loss_history = checkpoint.get(\"train_loss_history\", None)\n",
    "    test_acc_history = checkpoint.get(\"test_acc_history\", None)\n",
    "    label_mapping_comp = partial(label_mapping_base, mapping_sequence=mapping_sequence_comp)\n",
    "    label_mapping = partial(label_mapping_base, mapping_sequence=mapping_sequence)  \n",
    "    if_test = True\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_test:\n",
    "    # 测试\n",
    "    model.eval()\n",
    "    total_num_test = 0\n",
    "    true_num_main_test = 0\n",
    "    true_num_fx_test = 0\n",
    "    pbar_test = tqdm(loaders['test'], total=len(loaders['test']), desc=f\"Epo {0} Testing\", ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for x, y in pbar_test:\n",
    "            if x.get_device() == -1:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "            fx, X_main, X_comp, alpha = model(x, label_mapping, label_mapping_comp)\n",
    "\n",
    "            # 始终获取 X_main 和 fx 的预测结果\n",
    "            pred_labels_main = torch.argmax(X_main, dim=1)\n",
    "            pred_labels_fx = torch.argmax(fx, dim=1)\n",
    "\n",
    "            # 计算准确率\n",
    "            acc_main = pred_labels_main.eq(y).sum().item()\n",
    "            acc_fx = pred_labels_fx.eq(y).sum().item()\n",
    "\n",
    "            # 更新累积准确数\n",
    "            total_num_test += y.size(0)\n",
    "            true_num_main_test += acc_main\n",
    "            true_num_fx_test += acc_fx\n",
    "\n",
    "            # 计算并更新进度条显示，包含当前更新部分\n",
    "            overall_acc_main = 100 * true_num_main_test / total_num_test\n",
    "            overall_acc_fx = 100 * true_num_fx_test / total_num_test\n",
    "            pbar_test.set_postfix_str(f\" Acc_main: {overall_acc_main:.2f}% | Acc_fx: {overall_acc_fx:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca35eb1",
   "metadata": {},
   "source": [
    "# code for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8218e81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:08:35.197001Z",
     "start_time": "2025-01-13T08:08:35.184050Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "num_runs = 3  # 定义训练次数\n",
    "\n",
    "for run in range(1, num_runs + 1):\n",
    "    print(f\"\\n=== 开始第 {run} 次训练 ===\\n\")\n",
    "    \n",
    "    # 3. 加载预训练的模型并加载本地权重\n",
    "    if args.network == \"resnet18\":\n",
    "        from torchvision.models import resnet18\n",
    "        network = resnet18(weights=None)  # 初始化模型，不加载预训练权重\n",
    "        weight_path = os.path.join(args.model_dir, \"resnet18_weights.pth\")\n",
    "    elif args.network == \"resnet50\":\n",
    "        from torchvision.models import resnet50\n",
    "        network = resnet50(weights=None)  # 初始化模型，不加载预训练权重\n",
    "        weight_path = os.path.join(args.model_dir, \"resnet50_weights.pth\")\n",
    "    elif args.network == \"ViT_B32\":\n",
    "        from pytorch_pretrained_vit import ViT\n",
    "        network = ViT('B_32_imagenet1k', pretrained=False)  # 初始化模型，不加载预训练权重\n",
    "        weight_path = os.path.join(args.model_dir, \"ViT_B32_weights.pth\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{args.network} is not supported\")\n",
    "    \n",
    "    # 检查权重文件是否存在\n",
    "    if not os.path.exists(weight_path):\n",
    "        raise FileNotFoundError(f\"权重文件未找到: {weight_path}\")\n",
    "    \n",
    "    # 加载权重\n",
    "    network.load_state_dict(torch.load(weight_path, map_location=device, weights_only=True), strict=False)\n",
    "    network.to(device)\n",
    "    \n",
    "    print(f\"模型权重已加载至: {weight_path}\")\n",
    "    print(f\"模型设备: {device}\")\n",
    "    \n",
    "    # 冻结网络参数\n",
    "    network.requires_grad_(False)\n",
    "    network.eval()\n",
    "    \n",
    "    # 4. 初始化模型组件\n",
    "    visual_prompt = InstancewiseVisualPrompt(imgsize, attribute_layers, args.patch_size, args.attribute_channels).to(device)\n",
    "    visual_prompt_comp = VisualPrompt_compensation(imgsize, attribute_layers, args.patch_size, args.attribute_channels).to(device)\n",
    "    \n",
    "    mininet = PAC().to(device)\n",
    "    model = SMM_compensation(network, visual_prompt, visual_prompt_comp, mininet).to(device)\n",
    "    \n",
    "    # 5. 设置超参数\n",
    "    lr_visual_prompt_comp = 1e-2  # 优化器1的学习率\n",
    "    lr_visual_prompt = 1e-2       # 优化器2的学习率\n",
    "    gamma_prog = 0.8              # 优化器1的gamma\n",
    "    gamma_prompt = 0.8            # 优化器2的gamma\n",
    "    cycle_length = 55             # 每55个epoch为一个完整周期（25+25+5）\n",
    "    total_epochs = 600            # 总训练周期数（根据需要调整）\n",
    "    criterion = CustomLoss()\n",
    "    milestones = list(range(5, total_epochs + 1, 50))\n",
    "    \n",
    "    # 6. 定义优化器1：更新 visual_prompt_comp、criterion 和 mininet\n",
    "    optimizer1 = torch.optim.Adam([\n",
    "        {'params': model.visual_prompt_comp.parameters()},\n",
    "        {'params': criterion.parameters()},\n",
    "        {'params': model.mininet.parameters()}\n",
    "    ], lr=lr_visual_prompt_comp)\n",
    "    \n",
    "    scheduler1 = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer1,\n",
    "        milestones=milestones,\n",
    "        gamma=gamma_prog,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 7. 定义优化器2：更新 visual_prompt\n",
    "    optimizer2 = torch.optim.Adam([\n",
    "        {'params': model.visual_prompt.parameters()},\n",
    "    ], lr=lr_visual_prompt)\n",
    "    \n",
    "    scheduler2 = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer2,\n",
    "        milestones=milestones,\n",
    "        gamma=gamma_prompt,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 8. 初始化训练历史记录和收敛检测参数\n",
    "    # 这些变量将根据是否加载检查点进行条件初始化\n",
    "    # 初始化为 None，稍后根据情况进行赋值\n",
    "    train_loss_history = None\n",
    "    test_acc_history = None\n",
    "    best_acc = 0.0\n",
    "    scaler = None\n",
    "    patience = 20\n",
    "    threshold = 0.01\n",
    "    convergence_counter = None\n",
    "    converged = None\n",
    "    previous_best_acc = None\n",
    "    epoch_start_convergence = None\n",
    "    \n",
    "    # 9. 动态构建检查点文件名，添加运行后缀\n",
    "    dataset_name = args.dataset  # 'DTD' 等\n",
    "    checkpoint_path = os.path.join(save_path, f'best_AL_mish_{args.network}_{dataset_name}_{run}.pth')\n",
    "    checkpoint_path_ckpt = os.path.join(save_path, f'ckpt_AL_mish_{args.network}_{dataset_name}_{run}.pth')\n",
    "    \n",
    "    # 10. 检查是否有检查点存在\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"加载检查点：{checkpoint_path}\")\n",
    "        # 加载检查点\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.visual_prompt.load_state_dict(checkpoint['visual_prompt_dict'])\n",
    "        model.visual_prompt_comp.load_state_dict(checkpoint['visual_prompt_comp_dict'])\n",
    "        model.mininet.load_state_dict(checkpoint['mininet_dict'])\n",
    "        mapping_sequence = checkpoint.get(\"mapping_sequence\", None)\n",
    "        mapping_sequence_comp = checkpoint.get(\"mapping_sequence_comp\", None)\n",
    "        # 继续下一个epoch\n",
    "        epoch_start = checkpoint.get(\"epoch\", 0) + 1  \n",
    "        best_acc = checkpoint.get(\"best_acc\", 0.0)\n",
    "        optimizer1.load_state_dict(checkpoint['optimizer1_state_dict'])\n",
    "        optimizer2.load_state_dict(checkpoint['optimizer2_state_dict'])\n",
    "        scheduler1.load_state_dict(checkpoint['scheduler1_state_dict'])\n",
    "        scheduler2.load_state_dict(checkpoint['scheduler2_state_dict'])\n",
    "        criterion.load_state_dict(checkpoint['criterion_state_dict'])\n",
    "        \n",
    "        # 恢复训练历史和收敛检测参数\n",
    "        train_loss_history = checkpoint.get(\"train_loss_history\", [])\n",
    "        test_acc_history = checkpoint.get(\"test_acc_history\", [])\n",
    "        converged = checkpoint.get(\"converged\", False)\n",
    "        convergence_counter = checkpoint.get(\"convergence_counter\", 0)\n",
    "        previous_best_acc = checkpoint.get(\"previous_best_acc\", 0.0)\n",
    "        epoch_start_convergence = checkpoint.get(\"epoch_start_convergence\", 0)\n",
    "        \n",
    "        # 恢复 scaler 状态（如果保存了）\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler = GradScaler()\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        else:\n",
    "            scaler = GradScaler()\n",
    "        \n",
    "        print(f\"成功加载检查点，继续从 epoch {epoch_start} 开始训练。\")\n",
    "    else:\n",
    "        print(\"没有找到检查点，开始从头训练。\")\n",
    "        # 初始化训练历史记录和收敛检测参数\n",
    "        train_loss_history = []\n",
    "        test_acc_history = []\n",
    "        best_acc = 0.0\n",
    "        scaler = GradScaler()\n",
    "        \n",
    "        patience = 20            # 连续多少个epoch没有显著提升则认为收敛\n",
    "        threshold = 0.01         # 精度提升小于此阈值时认为没有显著提升\n",
    "        convergence_counter = 0  # 收敛计数器\n",
    "        converged = False        # 是否已收敛\n",
    "        previous_best_acc = 0.0  # 记录上一个最佳准确率\n",
    "        epoch_start_convergence = 0  # 收敛后的起始epoch\n",
    "        epoch_start = 0  # 从第0个epoch开始\n",
    "    \n",
    "    # 11. 开始训练\n",
    "    for epoch in range(epoch_start, total_epochs):  # 从加载的 epoch 开始\n",
    "        if args.mapping_method == 'ilm':\n",
    "            mapping_sequence_comp = generate_label_mapping_by_frequency(\n",
    "                model.visual_prompt_comp, model.network, loaders['train']\n",
    "            )\n",
    "            label_mapping_comp = partial(label_mapping_base, mapping_sequence=mapping_sequence_comp)\n",
    "            mapping_sequence = generate_label_mapping_by_frequency(\n",
    "                model.visual_prompt, model.network, loaders['train']\n",
    "            )\n",
    "            label_mapping = partial(label_mapping_base, mapping_sequence=mapping_sequence)\n",
    "    \n",
    "        model.visual_prompt.train()\n",
    "        model.visual_prompt_comp.train()\n",
    "        model.mininet.train()\n",
    "    \n",
    "        total_num = 0\n",
    "        true_num_main_train = 0\n",
    "        true_num_fx_train = 0\n",
    "        loss_sum = 0\n",
    "    \n",
    "        # 决定当前阶段\n",
    "        if not converged:\n",
    "            # 预训练阶段：仅训练主分支\n",
    "            updating_part = 'visual_prompt'\n",
    "            optimizer_main = [optimizer2]\n",
    "            scheduler_main = [scheduler2]\n",
    "        else:\n",
    "            # 交替训练阶段：周期性更新\n",
    "            epoch_in_cycle = (epoch - epoch_start_convergence) % cycle_length\n",
    "            if epoch_in_cycle < 25:\n",
    "                updating_part = 'visual_prompt_comp'\n",
    "                optimizer_main = [optimizer1]\n",
    "                scheduler_main = [scheduler1]\n",
    "            elif epoch_in_cycle < 50:\n",
    "                updating_part = 'visual_prompt'\n",
    "                optimizer_main = [optimizer2]\n",
    "                scheduler_main = [scheduler2]\n",
    "            else:\n",
    "                updating_part = 'all'\n",
    "                optimizer_main = [optimizer1, optimizer2]\n",
    "                scheduler_main = [scheduler1, scheduler2]\n",
    "    \n",
    "        pbar = tqdm(loaders['train'], total=len(loaders['train']),\n",
    "                    desc=f\"Epo {epoch}\", ncols=100)\n",
    "        for x, y in pbar:\n",
    "            if x.get_device() == -1:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "            pbar.set_description_str(f\"Epo {epoch}\", refresh=True)\n",
    "    \n",
    "            # 梯度清零\n",
    "            for opt in optimizer_main:\n",
    "                opt.zero_grad()\n",
    "    \n",
    "            with autocast():  # 混合精度训练\n",
    "                fx, X_main, X_comp, alpha = model(x, label_mapping, label_mapping_comp)\n",
    "                loss = criterion(fx, X_main, X_comp, alpha, y, updating_part=updating_part)\n",
    "    \n",
    "            scaler.scale(loss).backward()\n",
    "    \n",
    "            # 优化器步进\n",
    "            for opt in optimizer_main:\n",
    "                scaler.step(opt)\n",
    "            scaler.update()\n",
    "    \n",
    "            # 始终获取 X_main 和 fx 的预测结果\n",
    "            pred_labels_main = torch.argmax(X_main, dim=1)\n",
    "            pred_labels_fx = torch.argmax(fx, dim=1)\n",
    "    \n",
    "            # 计算准确率\n",
    "            acc_main = pred_labels_main.eq(y).sum().item()\n",
    "            acc_fx = pred_labels_fx.eq(y).sum().item()\n",
    "    \n",
    "            # 更新累积准确数\n",
    "            total_num += y.size(0)\n",
    "            true_num_main_train += acc_main\n",
    "            true_num_fx_train += acc_fx\n",
    "    \n",
    "            # 更新累积损失\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "    \n",
    "            # 计算并更新进度条显示，包含当前更新部分\n",
    "            overall_acc_main = 100 * true_num_main_train / total_num\n",
    "            overall_acc_fx = 100 * true_num_fx_train / total_num\n",
    "            pbar.set_postfix_str(f\"Updating: {updating_part} | Acc_main: {overall_acc_main:.2f}% | Acc_fx: {overall_acc_fx:.2f}%\")\n",
    "    \n",
    "        # 步进学习率调度器\n",
    "        for sch in scheduler_main:\n",
    "            sch.step()\n",
    "    \n",
    "        # 记录训练损失和准确率\n",
    "        train_loss = loss_sum / total_num\n",
    "        if not converged:\n",
    "            train_acc_main = true_num_main_train / total_num\n",
    "            train_loss_history.append(train_loss)\n",
    "            # 假设使用 TensorBoard 记录日志\n",
    "            logger.add_scalar(\"train/acc_main\", train_acc_main, epoch)\n",
    "            logger.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        else:\n",
    "            train_acc_main = true_num_main_train / total_num\n",
    "            train_acc_fx = true_num_fx_train / total_num\n",
    "            train_loss_history.append(train_loss)\n",
    "            logger.add_scalar(\"train/acc_main\", train_acc_main, epoch)\n",
    "            logger.add_scalar(\"train/acc_fx\", train_acc_fx, epoch)\n",
    "            logger.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "\n",
    "        # 测试\n",
    "        model.eval()\n",
    "        total_num_test = 0\n",
    "        true_num_main_test = 0\n",
    "        true_num_fx_test = 0\n",
    "        pbar_test = tqdm(loaders['test'], total=len(loaders['test']), desc=f\"Epo {epoch} Testing\", ncols=100)\n",
    "        with torch.no_grad():\n",
    "            for x, y in pbar_test:\n",
    "                if x.get_device() == -1:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                fx, X_main, X_comp, alpha = model(x, label_mapping, label_mapping_comp)\n",
    "    \n",
    "                # 始终获取 X_main 和 fx 的预测结果\n",
    "                pred_labels_main = torch.argmax(X_main, dim=1)\n",
    "                pred_labels_fx = torch.argmax(fx, dim=1)\n",
    "    \n",
    "                # 计算准确率\n",
    "                acc_main = pred_labels_main.eq(y).sum().item()\n",
    "                acc_fx = pred_labels_fx.eq(y).sum().item()\n",
    "    \n",
    "                # 更新累积准确数\n",
    "                total_num_test += y.size(0)\n",
    "                true_num_main_test += acc_main\n",
    "                true_num_fx_test += acc_fx\n",
    "    \n",
    "                # 计算并更新进度条显示，包含当前更新部分\n",
    "                overall_acc_main = 100 * true_num_main_test / total_num_test\n",
    "                overall_acc_fx = 100 * true_num_fx_test / total_num_test\n",
    "                pbar_test.set_postfix_str(f\"Updating: {updating_part} | Acc_main: {overall_acc_main:.2f}% | Acc_fx: {overall_acc_fx:.2f}%\")\n",
    "    \n",
    "        if not converged:\n",
    "            test_acc_history.append((overall_acc_main, None))\n",
    "            logger.add_scalar(\"test/acc_main\", overall_acc_main, epoch)\n",
    "        else:\n",
    "            test_acc_history.append((overall_acc_main, overall_acc_fx))\n",
    "            logger.add_scalar(\"test/acc_main\", overall_acc_main, epoch)\n",
    "            logger.add_scalar(\"test/acc_fx\", overall_acc_fx, epoch)\n",
    "    \n",
    "        # 定义 state_dict，确保在每个 epoch 中都被定义\n",
    "        state_dict = {\n",
    "            \"visual_prompt_dict\": model.visual_prompt.state_dict(),\n",
    "            \"visual_prompt_comp_dict\": model.visual_prompt_comp.state_dict(),\n",
    "            \"mininet_dict\": model.mininet.state_dict(),\n",
    "            \"mapping_sequence\": mapping_sequence,\n",
    "            \"mapping_sequence_comp\": mapping_sequence_comp,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_acc\": best_acc,\n",
    "            \"optimizer1_state_dict\": optimizer1.state_dict(),\n",
    "            \"optimizer2_state_dict\": optimizer2.state_dict(),\n",
    "            \"scheduler1_state_dict\": scheduler1.state_dict(),\n",
    "            \"scheduler2_state_dict\": scheduler2.state_dict(),\n",
    "            \"criterion_state_dict\": criterion.state_dict(),\n",
    "            \"train_loss_history\": train_loss_history,\n",
    "            \"test_acc_history\": test_acc_history,\n",
    "            # 添加收敛相关的状态\n",
    "            \"converged\": converged,\n",
    "            \"convergence_counter\": convergence_counter,\n",
    "            \"previous_best_acc\": previous_best_acc,\n",
    "            \"epoch_start_convergence\": epoch_start_convergence,\n",
    "            \"scaler_state_dict\": scaler.state_dict(),  # 保存 scaler 状态\n",
    "        }\n",
    "    \n",
    "        # 保存最佳模型\n",
    "        if not converged:\n",
    "            current_best_acc = overall_acc_main\n",
    "        else:\n",
    "            current_best_acc = overall_acc_fx  # 或根据需要选择\n",
    "    \n",
    "        if current_best_acc > best_acc:\n",
    "            best_acc = current_best_acc\n",
    "            state_dict[\"best_acc\"] = best_acc  # 更新 best_acc\n",
    "            torch.save(state_dict, checkpoint_path)\n",
    "            print(f\"保存最佳模型，准确率: {best_acc:.2f}%\")\n",
    "    \n",
    "        # 保存周期性检查点\n",
    "        torch.save(state_dict, checkpoint_path_ckpt)\n",
    "    \n",
    "        # 收敛检测逻辑\n",
    "        if not converged:\n",
    "            if epoch == epoch_start:\n",
    "                previous_best_acc = overall_acc_main\n",
    "                print(f\"Epoch {epoch+1}: 初始最佳准确率 = {previous_best_acc:.2f}%\")\n",
    "            else:\n",
    "                if (overall_acc_main - previous_best_acc) > threshold:\n",
    "                    previous_best_acc = overall_acc_main\n",
    "                    convergence_counter = 0\n",
    "                    print(f\"Epoch {epoch+1}: 准确率提升到 {overall_acc_main:.2f}%，更新最佳准确率。\")\n",
    "                else:\n",
    "                    convergence_counter += 1\n",
    "                    print(f\"Epoch {epoch+1}: 准确率未提升，收敛计数器 = {convergence_counter}/{patience}\")\n",
    "                    if convergence_counter >= patience:\n",
    "                        converged = True\n",
    "                        epoch_start_convergence = epoch + 1  # 记录收敛时的 epoch\n",
    "                        print(f\"主分支准确率已收敛（连续 {patience} 个epoch无显著提升），开始交替训练阶段。\")\n",
    "    \n",
    "        # 打印日志，包含当前更新部分和两种准确率，以及是否已收敛和数据集名称，并补充最高验证准确率\n",
    "        convergence_status = \"已收敛\" if converged else \"未收敛\"\n",
    "        print(f\"Epoch {epoch+1} 完成，数据集: {dataset_name}, 收敛状态: {convergence_status}, 更新部分: {updating_part}, 验证准确率 - Acc_main: {overall_acc_main:.2f}%, Acc_fx: {overall_acc_fx:.2f}%, 最高准确率: {best_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"第 {run} 次训练完成！\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688575a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8868d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32788a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "724.32px",
    "left": "21px",
    "top": "110.21px",
    "width": "304.51px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
